#!/usr/bin/env python3

"""
Plot script for Excel files generated by Oracle Crystal Ball.

This program can be fed the name of a Crystal Ball forecast, as
well as a number of Excel workbooks, as command-line arguments.
It will then generate histograms from the Monte Carlo simulation
data recorded in each workbook and plot the results together.
Statistical information about the results is also extracted and
written to dat-files with similar names as the Excel workbooks.

Usage:
  ./cbplot.py FORECAST FILE1 [FILE2 [...]]

Example:
  If you have two files `A.xlsx` and `B.xlsx` in the same directory
  as the script, and wish to plot their forecasts for "Result", run:
    ./cbplot.py "Result" "A.xlsx" "B.xlsx"
  The surrounding double quotes are in this case superfluous, but are
  required if the provided forecast name or filenames include spaces.

Notes:
  There are some tweakable parameters at the top of the source code,
  including the plot type (`plot`) and plot range (`dmin` and `dmax`).
"""

import sys
import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# Initialize plot style.
sns.set(rc={"figure.figsize": (4, 3)})
sns.set_style("ticks")
sns.set_palette("Set1")
sns.set_context("paper")

# Print an error and quit if no Excel workbooks were specified.
if len(sys.argv) < 3:
    print(f'Usage: {sys.argv[0]} "Forecast name" /path/to/workbook.xlsx [···]')
    print(f"\nSee the docstring in the source code for more documentation.")
    sys.exit(1)

# Which forecast variable to generate histograms for. This has to
# correspond to what the Crystal Ball forecast is named in Excel.
forecast = sys.argv[1]

# Read what workbooks to process from command-line arguments.
books = sys.argv[2:]

# This is the type of plots to generate. Set to 'hist' (histogram),
# 'kde' (kernel density estimation), or 'line' (histogram line plot).
plot = "line"

# This is the number of bins to use when generating histograms.
bin_num = 35

# Minimum and maximum value for the data elements to include.
# Change this if you need to discard some of the sampled data.
dmin = -np.inf
dmax = +np.inf

# Extract data from the provided workbooks:
data = []
pmin = +np.inf
pmax = -np.inf
for book in books:
    # Status information.
    print(f':: Processing "{book}"...')

    # Import all data from Excel workbook.
    try:
        sheets = pd.read_excel(book, sheet_name=None, header=None).values()
    except FileNotFoundError:
        print(f'Error: "{book}" is not a valid workbook.')
        sys.exit(1)

    # Determine where the relevant forecast trials start.
    try:
        rows = [np.where(sheet == "Trial values")[0][-1] for sheet in sheets]
        cols = [np.where(sheet == forecast)[1][-1] for sheet in sheets]
    except IndexError:
        print(f'Error: Not all sheets in "{book}" have trial values for "{forecast}".')
        sys.exit(1)

    # Determine where the relevant forecast trials stop.
    try:
        ends = [np.where(sheet == "Capability metrics")[0][-1] for sheet in sheets]
    except IndexError:
        ends = []

    # Extract and concatenate data from the relevant cells.
    if ends:
        cells = [
            sheet[cols[i]][rows[i] + 1 : ends[i] - 3] for i, sheet in enumerate(sheets)
        ]
    else:
        cells = [sheet[cols[i]][rows[i] + 1 :] for i, sheet in enumerate(sheets)]
    vals = np.concatenate([np.array(cell, dtype=float) for cell in cells])

    # Strip away NaN values from the array.
    vals = vals[~np.isnan(vals)]

    # Strip away too small and large values.
    vals = vals[(vals >= dmin) & (vals <= dmax)]

    # Accumulate the results in the data list.
    data.append(vals)

    # Calculate limiting percentiles from the results;
    # these are later used to select a histogram scale.
    pmid = np.median(vals)
    pmin = min(pmin, pmid - 3 * (pmid - np.percentile(vals, 15.87)))
    pmax = max(pmax, pmid - 3 * (pmid - np.percentile(vals, 84.13)))

    # Calculate other interesting statistics.
    results = {
        "points": len(vals),
        "median": np.median(vals),
        "mean": np.mean(vals),
        "mad": stats.median_absolute_deviation(vals),
        "std": np.std(vals),
        "min": np.min(vals),
        "P0.1": np.percentile(vals, 0.1),
        "P1.0": np.percentile(vals, 1.0),
        "P2.5": np.percentile(vals, 2.5),
        "P5.0": np.percentile(vals, 5.0),
        "P10.0": np.percentile(vals, 10.0),
        "P25.0": np.percentile(vals, 25.0),
        "P50.0": np.percentile(vals, 50.0),
        "P75.0": np.percentile(vals, 75.0),
        "P90.0": np.percentile(vals, 90.0),
        "P95.0": np.percentile(vals, 95.0),
        "P97.5": np.percentile(vals, 97.5),
        "P99.0": np.percentile(vals, 99.0),
        "P99.9": np.percentile(vals, 99.9),
        "max": np.max(vals),
    }

    # Write the statistics to output file.
    output = Path(book).with_suffix(".dat")
    print(f'   Writing stats to "{output}".')
    with open(output, "w") as f:
        f.write(f"# Crystal Ball statistics\n")
        f.write(f"# Workbook: {book}\n")
        f.write(f"# Forecast: {forecast}\n")
        for k, v in results.items():
            f.write("%-15s %.6g\n" % (k, v))
    print("")

# Create common histogram bins based on this scale.
bins = np.linspace(pmin, pmax, bin_num)

# Initialize a new matplotlib figure.
print(f":: Generating plots...")
fig, ax = plt.subplots()
ax.set_xlabel(forecast)
ax.set_ylabel("Probability density")

# Loop over all the data sets extracted above, and generate one plot
# from each one. Figure legends are autogenerated from file names.
if plot == "hist":
    # Version #1: Use histograms in the form of bar charts.
    for book, dat in zip(books, data):
        ax.hist(dat, bins, alpha=0.55, density=True, label=Path(book).stem)
elif plot == "line":
    # Version #2: Use histograms in the form of line plots.
    for book, dat in zip(books, data):
        hist = np.histogram(dat, bins, density=True)
        x = (hist[1][1:] + hist[1][:-1]) / 2
        y = hist[0]
        ax.plot(x, y, label=Path(book).stem)
elif plot == "kde":
    # Version #3: Use kernel density estimation instead.
    for book, dat in zip(books, data):
        pd.Series(dat).plot.kde(label=Path(book).stem)
else:
    print(f'Error: "{plot}" is not a valid plot type!')
    sys.exit(1)


# Update the axis ticks and limits.
ax.set_xlim([bins[0], bins[-1]])
ax.set_ylim([0, None])
ax.set_yticks([])

# Show legends only if multiple histograms are made.
if len(books) > 1:
    ax.legend(loc="upper right", frameon=False)

# Show the resulting combined plot.
plt.tight_layout()
plt.show()
